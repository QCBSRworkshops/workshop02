[["index.html", "Workshop 2: Loading and Manipulating Data QCBS R Workshop Series Preface 0.1 Code of conduct 0.2 Contributors 0.3 Contributing", " Workshop 2: Loading and Manipulating Data QCBS R Workshop Series Developed and maintained by the contributors of the QCBS R Workshop Series1 2022-03-23 22:28:18 Preface The QCBS R Workshop Series is a series of 10 workshops that walks participants through the steps required to use R for a wide array of statistical analyses relevant to research in biology and ecology. These open-access workshops were created by members of the QCBS both for members of the QCBS and the larger community. The content of this workshop has been peer-reviewed by several QCBS members. If you would like to suggest modifications, please contact the current series coordinators, listed on the main Github page. 0.1 Code of conduct The QCBS R Workshop Series and the QCBS R Symposium are venues dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. Participants, presenters and organizers of the workshop series and other related activities accept this Code of Conduct when being present at any workshop-related activities. We do not tolerate behaviour that is disrespectful or that excludes, intimidates, or causes discomfort to others. We do not tolerate discrimination or harassment based on characteristics that include, but are not limited to, gender identity and expression, sexual orientation, disability, physical appearance, body size, citizenship, nationality, ethnic or social origin, pregnancy, familial status, genetic information, religion or belief (or lack thereof), membership of a national minority, property, age, education, socio-economic status, technical choices, and experience level. It applies to all spaces managed by or affiliated with the workshop, including, but not limited to, workshops, email lists, and online forums such as GitHub, Slack and Twitter. 0.1.1 Expected behaviour All participants are expected to show respect and courtesy to others. All interactions should be professional regardless of platform: either online or in-person. In order to foster a positive and professional learning environment we encourage the following kinds of behaviours in all workshop events and platforms: Use welcoming and inclusive language Be respectful of different viewpoints and experiences Gracefully accept constructive criticism Focus on what is best for the community Show courtesy and respect towards other community members 0.1.2 Unacceptable behaviour Examples of unacceptable behaviour by participants at any workshop event/platform include: written or verbal comments which have the effect of excluding people on the - basis of membership of any specific group; causing someone to fear for their safety, such as through stalking or intimidation; violent threats or language directed against another person; the display of sexual or violent images; unwelcome sexual attention; nonconsensual or unwelcome physical contact; insults or put-downs; sexist, racist, homophobic, transphobic, ableist, or exclusionary jokes; incitement to violence, suicide, or self-harm; continuing to initiate interaction (including photography or recording) with - someone after being asked to stop; publication of private communication without consent. 0.2 Contributors Originally developed by: Johanna Bradie, Vincent Fugère, Thomas Lamy. Contributed with changes to the presentation: Contributed with changes to the written material: Contributed by reporting issues and suggesting modifications: 0.3 Contributing Under construction. The QCBS R Workshop Series is part of the Québec Centre for Biodiversity Science, and is maintained by the series coordinators and graduent student, postdoctoral, and research professional members. The contributors for this workshop can be accessed here.↩︎ "],["learning-objectives.html", "Chapter 1 Learning objectives", " Chapter 1 Learning objectives In this workshop, you will learn how to load, view, and manipulate your data in R. You will learn basic commands to inspect and visualize your data, and learn how to fix errors that may have occurred while loading your data into R. In addition, you will learn how to write an R script, which is a text file that contains your R commands and allows you to rerun your analyses in one simple touch of a key (or maybe two, or three…)! We have included an advance users section where we will introduce tidyr and dplyr, two powerful tools to manage and re-format your dataset, as well as apply simple or complex functions on subsets of your data. This workshop will be useful for those progressing through the entire workshop series, but also for those who already have some experience in R and would like to become proficient with new tools and packages. By the end of this workshop, we will have accomplished these objectives: Creating an R project Writing a script Loading, exploring and saving data Learn to manipulate data frames with tidyr, dplyr, maggritr "],["preparing-for-the-workshop.html", "Chapter 2 Preparing for the workshop", " Chapter 2 Preparing for the workshop All workshop materials are found at github.com/QCBSRworkshops/workshop02. This includes an R script which contains all code chunks shown in this book. For this workshop, we will be working with the following datasets: CO2, airquality and ChickWeight datasets To download this data, do right click + save on the page that opens. You should also make sure you have downloaded, installed, and loaded these packages: dplyr tidyr magrittr "],["rstudio-projects.html", "Chapter 3 RStudio Projects 3.1 Create a new project 3.2 Keep your files organized 3.3 Preparing data for R", " Chapter 3 RStudio Projects What is this? Projects make it easy to keep your work organized. All files, scripts, documentation related to a specific project are bound together with a .Rproj file Encourages reproducibility and easy sharing 3.1 Create a new project Use the Create project command (available in the Projects menu and the global toolbar) 3.2 Keep your files organized One project = one folder Place similar files inside of their own folders Keep track of versions 3.3 Preparing data for R Datasets should be stored as comma separated files (.csv) in Data folder. comma separated files (.csv) can be created from almost all applications (Excel, LibreOffice, GoogleDocs) file -&gt; save as .csv 3.3.1 Naming files Good: rawDatasetAgo2017.csv co2_concentrations_QB.csv 01_figIntro.R Bad: final.csv (Uninformative!) safnnejs.csv (Random!) 1-4.csv (Avoid using numbers!) Dont.separate.names.with.dots.csv (Can lead to reading file errors!) 3.3.2 Naming variables Use short informative titles (i.e. “Time_1” not “First time measurement”) Good: “Measurements”, “SpeciesNames”, “Site” Bad: “a”, “3”, “supercomplicatedverylongname” Column values must match their intended use 3.3.3 Common data preparation mistakes No text in numeric columns Do not include spaces! NA (not available) can be used for missing values, and blank entries will automatically be replaced with NA Name your variables informatively Look for typos! Avoid numeric values for data that do not have a numeric meaning (i.e. subject, replicate, treatment) For example, if subjects are “1,2,3” change to “A,B,C” or “S1,S2,S3” Use CONSISTENT formats for dates, numbers, metrics, etc. Do not include notes, additional headings, or merged cells! One variable per column! 3.3.4 Bad data examples It is possible to do all your data preparation work within R. This has several benefits: Saves time for large datasets Keeps original data intact Keeps track of the manipulation and transformation you did Can switch between long and wide format data very easily (more on this later and in workshop 4) For a useful resource, see https://www.zoology.ubc.ca/~schluter/R/data/ "],["writing-a-script.html", "Chapter 4 Writing a script", " Chapter 4 Writing a script An R script is a text file that contains all of the commands you will use. Once written and saved, your R script will allow you to make changes and re-run analyses with little effort. To use a script, just highlight commands and press “Run” or press command-enter (Mac) or ctrl-enter (PC). 4.0.1 Creating an R script 4.0.2 Commands &amp; Comments Use the ‘# symbol’ to denote comments in scripts. The ‘# symbol’ tells R to ignore anything remaining on a given line of the script when running commands. Since comments are ignored when running script, they allow you to leave yourself notes in your code or tell collaborators what you did. A script with comments is a good step towards reproducible science, and annotating someone’s script is a good way to learn. Try to be as detailed as possible! # This is a comment, not a command 4.0.3 Header It is recommended that you use comments to put a header at the beginning of your script with essential information: project name, author, date, version of R ## QCBS R Workshop ## Workshop 2 - Loading and manipulating ## data Author: Quebec Center for Biodiversity Science ## Date: Fall 2014 R version 2.15.0 4.0.4 Section Heading You can use four # signs in a row to create section headings to help organize your script. This allows you to move quickly between sections and hide sections. For example: #### Housekeeping #### RStudio displays a small arrow next to the line number where the section heading was created. If you click on the arrow, you will hide this section of the script. You can also move quickly between sections using the drop-down menu at the bottom of the script window. 4.0.5 Housekeeping The first command at the top of all scripts should be rm(list=ls()). This will clear R’s memory, and will help prevent errors such as using old data that has been left in your workspace. rm(list = ls()) # Clears R workspace `?`(rm) `?`(ls) We can test this command by adding data to the workspace and seeing how rm(list=ls()) will remove it. A &lt;- &quot;Test&quot; # Put some data in workspace A &lt;- &quot;Test&quot; # Add some spaces to organize your data! A = &quot;Test&quot; # You can do this, but it does not mean you should # Check objects in the workspace ls() # [1] &#39;A&#39; A # [1] &#39;Test&#39; Clean Workspace rm(list = ls()) A 4.0.6 Important Reminders R is ready for commands when you see the chevron ‘&gt;’ displayed in the terminal. If the chevron isn’t displayed, it means you typed an incomplete command and R is waiting for more input. Press ESC to exit and get R ready for a new command. R is case sensitive. i.e. “A” is a different object than “a” a &lt;- 10 A &lt;- 5 a A rm(list = ls()) # Clears R workspace again "],["loading-exploring-and-saving-data.html", "Chapter 5 Loading, exploring and saving data", " Chapter 5 Loading, exploring and saving data 5.0.1 Working directory R needs to know the directory where your data and files are stored in order to load them. You can see which directory you are currently working in by using the getwd() command. getwd() # This commands shows the directory you are currently working in When you load a script, R automatically sets the working directory to the folder containing the script. To change working directories using the setwd() function, specify the working directory’s path using a “/” to separate folders, subfolders and file names. You can also click Session &gt; Set working directory &gt; Choose directory… 5.0.2 Display the content of the working directory The command dir() displays the content of the working directory. dir() # This command shows the content of the directory you are currently working in You can check: Whether or not the file you plan to open is present in the current directory The correct spelling of the file name (e.g. ‘myfile.csv’ instead of ‘MyFile.csv’) 5.0.3 Importing data Use the read.csv() command to import data in R. CO2 &lt;- read.csv(&quot;co2_good.csv&quot;) # Creates an object called CO2 by loading data from a file called &#39;co2_good.csv&#39; This command specifies that you will be creating an R object named “CO2” by reading a csv file called “co2_good.csv”. This file must be located in your current working directory. Recall that the question mark can be used to find out what arguments the function requires. `?`(read.csv # Use the question mark to pull up the help page for a command ) In the help file you will note that adding the argument header=TRUE tells R that the first line of the spreadsheet contains column names and not data. CO2 &lt;- read.csv(&quot;co2_good.csv&quot;, header = TRUE) NOTE: If your operating system or CSV editor is in French, you may need to use read.csv2() instead of read.csv() Notice that RStudio now provides information on the CO2 data in your workspace. The workspace refers to all the objects that you create during an R session. 5.0.4 Looking at data The CO2 dataset consists of repeated measurements of CO2 uptake from six plants from Quebec and six plants from Mississippi at several levels of ambient CO2 concentration. Half of the plants of each type were chilled overnight before the experiment began. There are some common commands that are useful to look at imported data: CO2 Look at the whole data frame head(CO2) Look at the first few rows tail(CO2) Look at the last few rows names(CO2) Names of the columns in the data frame attributes(CO2) Attributes of the data frame dim(CO2) Dimensions of the data frame ncol(CO2) Number of columns nrow(CO2) Number of rows summary(CO2) Summary statistics str(CO2) Structure of the data frame The str() command is very useful to check the data type/mode for each column (i.e. to check that all factors are factors, and numeric data is stored as an integer or numeric. There are many common problems: Factors loaded as text (character) and vice versa Factors including too many levels because of a typo Numeric or integer data being loaded as a character due to a typo (including space or using a comma instead of a “.” for a decimal) Exercise Try to reload the data using: CO2 &lt;- read.csv(&quot;co2_good.csv&quot;, header = FALSE) Check the str() of CO2. What is wrong here? Reload the data with header=TRUE before continuing. 5.0.5 Reminder from workshop 1: Accessing data Data within a data frame can be extracted by several means. Let’s consider a data frame called mydata. Use square brackets to extract the content of a cell. mydata[2, 3] # extracts the content of row 2 / column 3 If column number is omitted, the whole row is extracted. mydata[1, ] # extracts the content of the first row The squared brackets can also be used recursively mydata[, 1][2] # this extracts the second content of the first column If row number is omitted, the whole column is extracted. Similarly, the $ sign followed by the corresponding header can be used. mydata$Variable1 # extracts a specific column by its name (&#39;Variable1&#39;) 5.0.6 Renaming variables Variable names (i.e. column names) can be changed within R. # First let&#39;s make a copy of the dataset to play with! CO2copy &lt;- CO2 # names() gives you the names of the variables present in # the data frame names(CO2copy) # Changing from English to French names (make sure you have # the same levels!) names(CO2copy) &lt;- c(&quot;Plante&quot;, &quot;Categorie&quot;, &quot;Traitement&quot;, &quot;conc&quot;, &quot;absortion&quot;) 5.0.7 Creating new variables New variables can be easily created and populated. For example, variables and strings can be concatenated together using the function paste(). # Let&#39;s create an unique id for our samples using the # function paste() see ?paste and ?paste0 Don&#39;t forget to # use &#39;&#39; for strings CO2copy$uniqueID &lt;- paste0(CO2copy$Plante, &quot;_&quot;, CO2copy$Categorie, &quot;_&quot;, CO2copy$Traitement) # Observe the results head(CO2copy$uniqueID) Creating new variables works for numbers and mathematical operations as well! # Let&#39;s standardize our variable &#39;absortion&#39; to relative # values CO2copy$absortionRel = CO2copy$absortion/max(CO2copy$absortion) # Changing to relative values # Observe the results head(CO2copy$absortionRel) 5.0.8 Subsetting data There are many ways to subset a data frame. # Let&#39;s keep working with our CO2copy data frame ## Subsetting by variable name CO2copy[, c(&quot;Plante&quot;, &quot;absortionRel&quot;)] # Selects only &#39;Plante&#39; and &#39;absortionRel&#39; columns. (Don&#39;t forget the &#39;,&#39;!) ## Subsetting by row CO2copy[1:50, ] # Subset data frame from rows from 1 to 50 ### Subsetting by matching with a factor level CO2copy[CO2copy$Traitement == &quot;nonchilled&quot;, ] # Select observations matching only the nonchilled Traitement. ### Subsetting according to a numeric condition CO2copy[CO2copy$absortion &gt;= 20, ] # Select observations with absortion higher or equal to 20 ### Conditions can be complimentary -The &amp; (and) argument- CO2copy[CO2copy$Traitement == &quot;nonchilled&quot; &amp; CO2copy$absortion &gt;= 20, ] # We are done playing with the dataset copy. Let&#39;s erase # it. rm(CO2copy) Go here to check all the logical operators you can use to subset a data frame in R 5.0.9 Data exploration A good way to start your data exploration is to look at some basic statistics of your dataset using the summary() function. summary(CO2) # Get summary statistics of your dataset You can also use some other functions to calculate basic statistics about specific parts of your data frame, using mean(), sd(), hist(), and print(). # Calculate mean and standard deviation of the # concentration, and assign them to new variables meanConc &lt;- mean(CO2$conc) sdConc &lt;- sd(CO2$conc) # print() prints any given value to the R console print(paste(&quot;the mean of concentration is:&quot;, meanConc)) print(paste(&quot;the standard deviation of concentration is:&quot;, sdConc)) # Let&#39;s plot a histogram to explore the distribution of # &#39;uptake&#39; hist(CO2$uptake) # Increasing the number of bins to observe better the # pattern hist(CO2$uptake, breaks = 40) The function apply() can be used to apply a function to multiple columns of your data simultaneously. Use the ?apply command to get more information about apply(). `?`(apply) To use apply, you have to specify three arguments. The first argument is the data you would like to apply the function to; the second argument is whether you would like to calculate based on rows (1) or columns (2) of your dataset; the third argument is the function you would like to apply. For example: apply(CO2[, 4:5], MARGIN = 2, FUN = mean) # Calculate mean of the two columns in the data frame that contain continuous data 5.0.10 Save your workspace By saving your workspace, you can save the script and the objects currently loaded into R. If you save your workspace, you can reload all of the objects even after you use the rm(list=ls()) command to delete everything in the workspace. Use save.image() to save the workplace: save.image(file = &quot;co2_project_Data.RData&quot;) # Save workspace rm(list = ls()) # Clears R workspace load(&quot;co2_project_Data.RData&quot;) #Reload everything that was in your workspace head(CO2) # Looking good! :) 5.0.11 Exporting data If you want to save a data file that you have created or edited in R, you can do so using the write.csv() command. Note that the file will be written into the current working directory. write.csv(CO2, file = &quot;co2_new.csv&quot;) # Save object CO2 to a file named co2_new.csv 5.0.12 Use your data CHALLENGE Try to load, explore, plot and save your own data in R. Does it load properly? If not, try fixing it in R. Save your fixed data and then try opening it in Excel. "],["repairing-a-broken-data-frame.html", "Chapter 6 Repairing a Broken Data Frame", " Chapter 6 Repairing a Broken Data Frame Data can be messy, there are compatibility issues. For example, sharing data from a Mac to Windows or between computers set up in different continents can lead to weird datasets. Let’s practice how to solve some common errors. 6.0.1 Fix a broken dataframe # Read co2_broken.csv file into R and find the problems CO2 &lt;- read.csv(&quot;co2_broken.csv&quot;) # Overwrite CO2 object with broken CO2 data head(CO2) # Looks messy CO2 # Indeed! This is probably what your data or downloaded data looks like. You can fix the data frame in R (or not…) Give it a try before looking at the solution! Work with your neighbours and have fun :) Some useful functions: ?read.csv head() str() class() unique() levels() which() droplevels() Note: For these functions you have to put the name of the data object in the parentheses (i.e. head(CO2)). Also remember that you can use “?” to look up help for a function (i.e. ?str). HINT: There are 4 problems! Problem #1: The data appears to be lumped into one column Solution: Re-import the data, but specify the separation among entries. The sep argument tells R what character separates the values on each line of the file. Here, “TAB” was used instead of “,”. CO2 &lt;- read.csv(&quot;co2_broken.csv&quot;, sep = &quot;&quot;) `?`(read.csv) Problem #2: The data does not start until the third line of the txt file, so you end up with notes on the file as the headings. head(CO2) # The head() command allows you to see that the data has not been read in with the proper headings Solution: To fix this problem, you can tell R to skip the first two rows when reading in this file. CO2 &lt;- read.csv(&quot;co2_broken.csv&quot;, sep = &quot;&quot;, skip = 2) # By adding the skip argument into the read.csv function, R knows to skip the first two rows head(CO2) # You can now see that the CO2 object has the appropriate headings Problem #3: “conc” and “uptake” variables are considered factors instead of numbers, because there are comments/text in the numeric columns. str(CO2) # The str() command shows you that both &#39;conc&#39; and &#39;uptake&#39; are labelled as factors class(CO2$conc) unique(CO2$conc) # By looking at the unique values in this column, you see that both columns contain &#39;cannot_read_notes&#39; unique(CO2$uptake) `?`(unique) Solution: `?`(read.csv) CO2 &lt;- read.csv(&quot;co2_broken.csv&quot;, sep = &quot;&quot;, skip = 2, na.strings = c(&quot;NA&quot;, &quot;na&quot;, &quot;cannot_read_notes&quot;)) By identifying “cannot_read_notes” as NA data, R reads these columns properly. Remember that NA (capital!) stands for not available. head(CO2) str(CO2) # You can see that conc variable is now an integer and the uptake variable is now treated as numeric Problem #4: There are only two treatments (chilled and nonchilled) but there are spelling errors causing it to look like 4 different treatments. str(CO2) # You can see that 4 levels are listed for Treatment levels(CO2$Treatment) unique(CO2$Treatment) # The 4 different treatments are &#39;nonchilled&#39;, &#39;nnchilled&#39;, &#39;chilled&#39;, and &#39;chiled&#39; Solution: # You can use which() to find rows with the typo # &#39;nnchilled&#39; which(CO2$Treatment == &quot;nnchilled&quot;) # Row number ten # You can then correct the error using indexing: CO2$Treatment[10] &lt;- &quot;nonchilled&quot; # Alternatively, doing it with a single command: CO2$Treatment[which(CO2$Treatment == &quot;nnchilled&quot;)] &lt;- &quot;nonchilled&quot; # Now doing the same for &#39;chiled&#39;: CO2$Treatment[which(CO2$Treatment == &quot;chiled&quot;)] &lt;- &quot;chilled&quot; Have we fixed the problem? str(CO2) # Structure still identifies 4 levels of the factor unique(CO2$Treatment) # But, unique says that only two are used CO2 &lt;- droplevels(CO2) # This command drops the unused levels from all factors in the data frame str(CO2) # Fixed! "],["manipulate-data-with-the-tidyverse.html", "Chapter 7 Manipulate data with the tidyverse 7.1 Data manipulation with dplyr 7.2 dplyr and magrittr, a match made in heaven 7.3 dplyr - grouped operations and summaries 7.4 dplyr - Merging data frames", " Chapter 7 Manipulate data with the tidyverse 7.0.1 Using tidyr to reshape data frames 7.0.2 Why “tidy” your data? Tidying allows you to manipulate the structure of your data while preserving all original information. Many functions in R require (or work better) with a data structure that isn’t always easily readable by people. In contrast to aggregation, which reduces many cells in the original data set to one cell in the new dataset, tidying preserves a one-to-one connection. Although aggregation can be done with many functions in R, the tidyr package allows you to both reshape and aggregate within a single syntax. Install / Load the tidyr() package: if (!require(tidyr)) { install.packages(&quot;tidyr&quot;) } library(tidyr) 7.0.3 Wide vs. long data Wide format data has a separate column for each variable or each factor in your study. One row therefore can therefore include several different observations. Long format data has a column stating the measured variable types and a column containing the values associated to those variables (each column is a variable, each row is one observation). This is considered “tidy” data because it is easily interpreted by most packages for visualization and analysis in R. The format of your data depends on your specific needs, but some functions and packages such as dplyr, lm(), glm(), gam() require long format data. The ggplot2 package can use wide data format for some basic plotting, but more complex plots require the long format (example to come). Additionally, long form data can more easily be aggregated and converted back into wide form data to provide summaries, or to check the balance of sampling designs. We can use the tidyr package to to manipulate the structure of your data while preserving all original information, using the following functions: pivot_longer() our data (wide --&gt; long) pivot_wider() our data (long --&gt; wide) Let’s pretend you send out your field assistant to measure the diameter at breast height (DBH) and height of three tree species for you. The result is this “wide” data set. &gt; wide &lt;- data.frame(Species = c(&quot;Oak&quot;, &quot;Elm&quot;, &quot;Ash&quot;), DBH = c(12, 20, 13), Height = c(56, 85, 55)) &gt; wide Species DBH Height 1 Oak 12 56 2 Elm 20 85 3 Ash 13 55 7.0.4 pivot_longer(): Making your data long `?`(pivot_longer) Most of the packages in the Hadleyverse will require long format data where each row is an entry and each column is a variable. Let’s try to “gather” the this wide data using the pivot_longer() function in tidyr. pivot_longer() takes multiple columns, and gathers them into key-value pairs. The function requires at least 3 arguments: data: a data frame (e.g. “wide”) cols: name or numeric index of the columns we wish to gather names_to: name of the new column containing variable names (e.g. “Measurement”) values_to: name of the new column containing variable values (e.g. “Value”) (e.g. “DBH” or “Height”) # Gathering columns into rows &gt; long &lt;- pivot_longer(data = wide, cols = c(&quot;DBH&quot;, &quot;Height&quot;), names_to = &quot;dimension&quot;, values_to = &quot;cm&quot;) &gt; long Species dimension cm &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 Chene DHP 12 2 Chene Haut 56 3 Orme DHP 20 4 Orme Haut 85 5 Frene DHP 13 6 Frene Haut 55 Let’s try this with the C02 dataset. Here we might want to collapse the last two quantitative variables: CO2.long &lt;- pivot_longer(CO2, cols = c(&quot;conc&quot;, &quot;uptake&quot;), &quot;response&quot;, &quot;value&quot;) head(CO2) head(CO2.long) tail(CO2.long) 7.0.5 pivot_wider(): Making your data wide pivot_wider() uses the same syntax as pivot_longer(). The function requires 3 arguments: data: A data frame (e.g. “long”) names_from: Name of the column containing variable names (e.g. “Measurement”) values_from: Name of the column containing variable values (e.g. “Value”) # Spreading rows into columns &gt; wide2 &lt;- ivot_wider(data = long, names_from = &quot;dimension&quot;, values_from = &quot;cm&quot;) &gt; wide2 Species DBH Height &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Oak 12 56 2 Elm 20 85 3 Ash 13 55 7.0.6 A tibble structure for your data Tibble is an alternate, more convenient, version for a data frame. Using tibble ensures good coding practices that can be missed using data.frame. For instance, it does not change the type of inputs (e.g. string to factors). tibble(x = 1:3, y = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) In addition, tibble simplifies the use of nested lists. tibble(x = 1:3, y = list(1:5, 1:10, 1:20)) You can use with a tibble all the functions applied to a data.frame. 7.0.7 separate(): Separate two (or more) variables in a single column Some times you might have really messy data that has two variables in one column. Thankfully the separate() function can (wait for it) separate the two variables into two columns. The separate() function splits a columns by a character string separator. It requires 4 arguments: data: A data frame (e.g. “long”) col: Name of the column you wish to separate into: Names of new variables to create sep: Character which indicates where to separate Let’s create a really messy data set: set.seed(8) messy &lt;- data.frame(id = 1:4, trt = sample(rep(c(&quot;control&quot;, &quot;farm&quot;), each = 2)), zooplankton.T1 = runif(4), fish.T1 = runif(4), zooplankton.T2 = runif(4), fish.T2 = runif(4)) messy First, we want to convert this wide dataset to long format. messy.long &lt;- pivot_longer(messy, names_to = &quot;taxa&quot;, cols = c(&quot;zooplankton.T1&quot;, &quot;fish.T1&quot;, &quot;zooplankton.T2&quot;, &quot;fish.T2&quot;)) head(messy.long) id trt taxa value &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 farm zooplankton.T1 0.719 2 1 farm fish.T1 0.644 3 1 farm zooplankton.T2 0.545 4 1 farm fish.T2 0.264 5 2 farm zooplankton.T1 0.291 6 2 farm fish.T1 0.457 Then, we want to split those two sampling times (T1 &amp; T2). The syntax we use here is to tell R separate(data, what column, into what, by what). The tricky part here is telling R where to separate the character string in your column entry using a regular expression to describe the character that separates them. Here, the string should be separated by the period \".\". messy.long.sep &lt;- separate(messy.long, taxa, into = c(&quot;species&quot;, &quot;time&quot;), sep = &quot;\\\\.&quot;) head(messy.long.sep) id trt species time value &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 farm zooplankton T1 0.719 2 1 farm fish T1 0.644 3 1 farm zooplankton T2 0.545 4 1 farm fish T2 0.264 5 2 farm zooplankton T1 0.291 6 2 farm fish T1 0.457 The argument sep = \"\\.\" tells R to splits the character string around the period (.). We cannot type directly \".\" because it is a regular expression that matches any single character. 7.0.8 Recap: tidyr tidyr is a package that reshapes the layout of data sets. Convert from wide format to long format using gather() Convert from long format to wide format using spread() Split and merge columns with unite() and separate() Here’s cheat sheet to help you use tidyr and dplyr for more data wrangling: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf 7.0.9 tidyr CHALLENGE Using the airquality dataset, gather() all the columns (except Month and Day) into rows. Then spread() the resulting dataset to return the same data format as the original data. `?`(air.quality) data(airquality) 7.0.10 Solution # Use gather() to convert the dataset to long format air.long &lt;- gather(airquality, variable, value, -Month, -Day) head(air.long) # Note that the syntax used here indicates we wish to # gather ALL the columns except &#39;Month&#39; and &#39;Day&#39; # Then, use spread() to convert the dataset back to wide # format air.wide &lt;- spread(air.long, variable, value) head(air.wide) 7.0.11 tidyr CHALLENGE 2 Spread the resulting data frame to return to the original data format. 7.0.12 Solution air.wide &lt;- pivot_wider(air.long, values_from = &quot;value&quot;, names_from = &quot;variable&quot;) head(air.wide) 7.1 Data manipulation with dplyr 7.1.1 Intro to dplyr The vision of the dplyr package is to simplify data manipulation by distilling all the common data manipulation tasks to a set of intuitive functions (or “verbs”). The result is a comprehensive set of tools that facilitates data manipulation, such as filtering rows, selecting specific columns, re-ordering rows, adding new columns and summarizing data. In addition to ease of use, it is also an amazing package because: it can crunch huge datasets wicked fast (written in Cpp) it plays nice with the RStudio IDE and other packages in the Hadleyverse it can interface with external databases and translate your R code into SQL queries if Batman was an R package, he would be dplyr (mastering fear of data, adopting cool technologies) Certain R base functions work similarly to dplyr functions, including: split(), subset(), apply(), sapply(), lapply(), tapply() and aggregate() Let’s install and load the dplyr package: if (!require(dplyr)) { install.packages(&quot;dplyr&quot;) } library(dplyr) The dplyr package is built around a core set of “verbs” (or functions). We will start with the following 4 verbs because these operations are ubiquitous in data manipulation: select(): select columns from a data frame filter(): filter rows according to defined criteria arrange(): re-order data based on criteria (e.g. ascending, descending) mutate(): create or transform values in a column 7.1.2 Select a subset of columns with select() The general syntax for this function is select(dataframe, column1, column2, ...). Most dplyr functions will follow a similarly simple syntax. select() requires at least 2 arguments: data: the dataset to manipulate …: column names, positions, or complex expressions (separated by commas) For example: select(data, column1, column2) # select columns 1 and 2 select(data, c(2:4,6) # select columns 2 to 4 and 6 select(data, -column1) # select all columns except column 1 select(data, start_with(x.)) # select all columns that start with &quot;x.&quot; Here are more examples of how to use select(): The airquality dataset contains several columns: &gt; head(airquality) Ozone Solar.R Wind Temp Month Day 1 41 190 7.4 67 5 1 2 36 118 8.0 72 5 2 3 12 149 12.6 74 5 3 4 18 313 11.5 62 5 4 5 NA NA 14.3 56 5 5 6 28 NA 14.9 66 5 6 For example, suppose we are only interested in the variation of “Ozone” over time within the airquality dataset, then we can select the subset of required columns for further analysis: &gt; ozone &lt;- select(airquality, Ozone, Month, Day) &gt; head(ozone) Ozone Month Day 1 41 5 1 2 36 5 2 3 12 5 3 4 18 5 4 5 NA 5 5 6 28 5 6 7.1.3 Select a subset of rows with filter() A common operation in data manipulation is the extraction of a subset based on specific conditions. The general syntax for this function is filter(dataframe, logical statement 1, logical statement 2, ...). Remember that logical statements provide a TRUE or FALSE answer. The filter() function retains all the data for which the statement is TRUE. This can also be applied on characters and factors. Here is a useful reminder of how logic works in R. For example, in the airquality dataset, suppose we are interested in analyses that focus on the month of August during high temperature events: &gt; august &lt;- filter(airquality, Month == 8, Temp &gt;= 90) &gt; head(august) Ozone Solar.R Wind Temp Month Day 1 89 229 10.3 90 8 8 2 110 207 8.0 90 8 9 3 NA 222 8.6 92 8 10 4 76 203 9.7 97 8 28 5 118 225 2.3 94 8 29 6 84 237 6.3 96 8 30 7.1.4 Sorting rows with arrange() In data manipulation, we sometimes need to sort our data (e.g. numerically or alphabetically) for subsequent operations. A common example of this is a time series. The arrange() function re-orders rows by one or multiple columns, using the following syntax: arrange(data, variable1, variable2, ...). By default, rows are sorted in ascending order. Note that we can also sort in descending order by placing the target column in desc() inside the arrange() function as follows: arrange(data, variable1, desc(variable2), ...). Example: Let’s use the following code to create a scrambled version of the airquality dataset &gt; air_mess &lt;- sample_frac(airquality, 1) &gt; head(air_mess) Ozone Solar.R Wind Temp Month Day 21 1 8 9.7 59 5 21 42 NA 259 10.9 93 6 11 151 14 191 14.3 75 9 28 108 22 71 10.3 77 8 16 8 19 99 13.8 59 5 8 104 44 192 11.5 86 8 12 Now, let’s arrange the data frame back into chronological order, sorting by Month, and then by Day: &gt; air_chron &lt;- arrange(air_mess, Month, Day) &gt; head(air_chron) Ozone Solar.R Wind Temp Month Day 1 41 190 7.4 67 5 1 2 36 118 8.0 72 5 2 3 12 149 12.6 74 5 3 4 18 313 11.5 62 5 4 5 NA NA 14.3 56 5 5 6 28 NA 14.9 66 5 6 Try to see the difference when we change the order of the target columns: arrange(air_mess, Day, Month) 7.1.5 Create and populate columns with mutate() Besides subsetting or sorting your data frame, you will often require tools to transform your existing data or generate some additional data based on existing variables. We can use the function mutate() to compute and add new columns in your dataset. The mutate() function follows this syntax: mutate(data, newVar1 = expression1, newVar2 = expression2, ...). Let’s create a new column using mutate(). For example, suppose we would like to convert the temperature variable from degrees Fahrenheit to degrees Celsius: &gt; airquality_C &lt;- mutate(airquality, Temp_C = (Temp-32)*(5/9)) &gt; head(airquality_C) Ozone Solar.R Wind Temp Month Day Temp_C 1 41 190 7.4 67 5 1 19.44444 2 36 118 8.0 72 5 2 22.22222 3 12 149 12.6 74 5 3 23.33333 4 18 313 11.5 62 5 4 16.66667 5 NA NA 14.3 56 5 5 13.33333 6 28 NA 14.9 66 5 6 18.88889 Note that the syntax here is quite simple, but within a single call of the mutate() function, we can replace existing columns, we can create multiple new columns, and each new column can be created using newly created columns within the same function call. 7.2 dplyr and magrittr, a match made in heaven The magrittr package brings a new and exciting tool to the table: a pipe operator. Pipe operators provide ways of linking functions together so that the output of a function flows into the input of next function in the chain. The syntax for the magrittr pipe operator is %&gt;%. The magrittr pipe operator truly unleashes the full power and potential of dplyr, and we will be using it for the remainder of the workshop. First, let’s install and load it: if (!require(magrittr)) { install.packages(&quot;magrittr&quot;) } require(magrittr) Using it is quite simple, and we will demonstrate that by combining some of the examples used above. Suppose we wanted to filter() rows to limit our analysis to the month of June, then convert the temperature variable to degrees Celsius. We can tackle this problem step by step, as before: june_C &lt;- mutate(filter(airquality, Month == 6), Temp_C = (Temp - 32) * (5/9)) This code can be difficult to decipher because we start on the inside and work our way out. As we add more operations, the resulting code becomes increasingly illegible. Instead of wrapping each function one inside the other, we can accomplish these 2 operations by linking both functions together: june_C &lt;- airquality %&gt;% filter(Month == 6) %&gt;% mutate(Temp_C = (Temp - 32) * (5/9)) Notice that within each function, we have removed the first argument which specifies the dataset. Instead, we specify our dataset first, then “pipe” into the next function in the chain. The advantages of this approach are that our code is less redundant and functions are executed in the same order we read and write them, which makes its easier and quicker to both translate our thoughts into code and read someone else’s code and grasp what is being accomplished. As the complexity of your data manipulations increases, it becomes quickly apparent why this is a powerful and elegant approach to writing your dplyr code. Quick tip: In RStudio we can insert this pipe quickly using the following hotkey: Ctrl (or Cmd for Mac) +Shift+M. 7.3 dplyr - grouped operations and summaries The dplyr verbs we have explored so far can be useful on their own, but they become especially powerful when we link them with each other using the pipe operator (%&gt;%) and by applying them to groups of observations. The following functions allow us to split our data frame into distinct groups on which we can then perform operations individually, such as aggregating/summarising: group_by(): group data frame by a factor for downstream commands (usually summarise) summarise(): summarise values in a data frame or in groups within the data frame with aggregation functions (e.g. min(), max(), mean(), etc…) These verbs provide the needed backbone for the Split-Apply-Combine strategy that was initially implemented in the plyr package on which dplyr is built. Let’s demonstrate the use of these with an example using the airquality dataset. Suppose we are interested in the mean temperature and standard deviation within each month: &gt; month_sum &lt;- airquality %&gt;% group_by(Month) %&gt;% summarise(mean_temp = mean(Temp), sd_temp = sd(Temp)) &gt; month_sum Source: local data frame [5 x 3] Month mean_temp sd_temp (int) (dbl) (dbl) 1 5 65.54839 6.854870 2 6 79.10000 6.598589 3 7 83.90323 4.315513 4 8 83.96774 6.585256 5 9 76.90000 8.355671 7.3.1 dplyr &amp; magrittr CHALLENGE Using the ChickWeight dataset, create a summary table which displays the difference in weight between the maximum and minimum weight of each chick in the study. Employ dplyr verbs and the %&gt;% operator. `?`(ChickWeight) data(ChickWeight) 7.3.2 Solution # Use group_by() to divide the dataset by &quot;Chick&quot; # Use summarise() to calculate the weight gain within each group &gt; weight_diff &lt;- ChickWeight %&gt;% group_by(Chick) %&gt;% summarise(weight_diff = max(weight) - min(weight)) &gt; weight_diff Source: local data frame [50 x 2] Chick weight_diff (fctr) (dbl) 1 18 4 2 16 16 3 15 27 4 13 55 5 9 58 6 20 76 7 10 83 8 8 92 9 17 100 10 19 114 .. ... ... Note that we are only calculating the difference between max and min weight. This doesn’t necessarily correspond to the difference in mass between the beginning and the end of the trials. Closely inspect the data for chick # 18 to understand why this is the case: &gt; chick_18 &lt;- ChickWeight %&gt;% filter(Chick == 18) &gt; chick_18 weight Time Chick Diet 1 39 0 18 1 2 35 2 18 1 Here we notice that chick 18 has in fact lost weight (and probably died during the trial). From a scientific perspective, perhaps a more interesting question is which of the 4 diets results in the greatest weight gain in chicks. We could calculate this using 2 more useful dplyr functions: first() and last() allow us to access the (need I say respectively) first and last observation within a group. ++++ 7.3.3 dplyr &amp; magrittr NINJA CHALLENGE Using the ChickWeight dataset, create a summary table which displays, for each diet, the average individual difference in weight between the end and the beginning of the study. Employ dplyr verbs and the %&gt;% operator. (Hint: first() and last() may be useful here.) 7.3.4 Ninja hint Note that we can group the data frame using more than one factor, using the general syntax as follows: group_by(group1, group2, ...) Within group_by(), the multiple groups create a layered onion, and each subsequent single use of the summarise() function peels off the outer layer of the onion. In the above example, after we carried out a summary operation on group2, the resulting data set would remain grouped by group1 for downstream operations. 7.3.5 Solution &gt; diet_summ &lt;- ChickWeight %&gt;% group_by(Diet, Chick) %&gt;% summarise(weight_gain = last(weight) - first(weight)) %&gt;% group_by(Diet) %&gt;% summarise(mean_gain = mean(weight_gain)) &gt; diet_summ # A tibble: 4 × 2 Diet mean_gain &lt;fctr&gt; &lt;dbl&gt; 1 1 114.9 2 2 174.0 3 3 229.5 4 4 188.3 Given that the solution to the last challenge requires that we compute several operations in sequence, it provides a nice example to demonstrate why the syntax implemented by dplyr and magrittr. An additional challenge (if you are well versed in base R functions) would to reproduce the same operations using fewer key strokes. We tried, and failed… Perhaps we are too accustomed to dplyr now. ++++ 7.4 dplyr - Merging data frames In addition to all the operations we have explored, dplyr also provides some functions that allow you to join two data frames together. The syntax in these functions is simple relative to alternatives in other R packages: left_join() right_join() inner_join() anti_join() These are beyond the scope of the current introductory workshop, but they provide extremely useful functionality you may eventually require for some more advanced data manipulation needs. "],["summary.html", "Chapter 8 Summary", " Chapter 8 Summary R is… In the next workshop, … "],["additional-resources.html", "Chapter 9 Additional resources", " Chapter 9 Additional resources 9.0.0.1 Cheat Sheets The RStudio Data Wrangling Cheat Sheet 9.0.0.2 A few books Myers RH - Classical and Modern Regression with Application Gotelli NJ - A Primer of Ecological Statistics 9.0.0.3 A few useful links Learn more about dplyr Sean Anderson’s Intro to dplyr and pipes Bradley Boehmke’s Intro to data wrangling "],["references.html", "Chapter 10 References", " Chapter 10 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
